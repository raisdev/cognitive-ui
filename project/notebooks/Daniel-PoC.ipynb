{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519f4790-aaaa-42ca-9370-186209e65c4a",
   "metadata": {},
   "source": [
    "<h1> Set-up </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b111544d-f027-4cee-a28b-104400d3458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "from langchain.tools import tool\n",
    "from pydantic.v1 import BaseModel, Field\n",
    "from IPython.display import display, HTML\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.agent import AgentFinish\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aee55bf-97c3-482f-82b0-5e8ee8875957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting your personal OPENAI Api Key\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab0c62f-dbfe-4e50-8ea3-0b959df9be5a",
   "metadata": {},
   "source": [
    "<h1> Initializing Tools </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e29423-eda9-46de-a53e-e792939e4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Design_logo_input(BaseModel):\n",
    "    topic: str = Field(..., description=\"The topic for which the logo should be designed for. For example, if the topic were 'ice-cream shop' then the logo returned would be a logo fit for the ice-cream shop to put on their sign and merchandise.\")\n",
    "\n",
    "@tool(args_schema=Design_logo_input)\n",
    "def design_logo_concepts(topic: str) -> str:\n",
    "    \"\"\"Returns the url for a logo design that is based on the provided topic\"\"\"\n",
    "    # Currently a very empty function\n",
    "    return f\"s3://designs/logo_{len(topic)%5+1}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adfdc74-9ef8-412c-b726-7af14234d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UI_Output_Request(BaseModel):\n",
    "    inpt: str = Field(... , description=f\"A description of the UI function you want and how you would call it along with the arguments you would use\")\n",
    "\n",
    "@tool(args_schema=UI_Output_Request)\n",
    "def ui_output_request(inpt: str) -> str:\n",
    "    \"\"\"Provides a convenient way for you to describe what UI function you want and what to call it with without actually calling a UI function.\"\"\"\n",
    "    return inpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6df5894-28d6-42d8-8de8-91c494fcc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product_UI_input(BaseModel):\n",
    "    path: str = Field(... , description=f\"The path of the image for the UI page. If no image is wanted or required provide an empty string.\")\n",
    "\n",
    "@tool(args_schema=Product_UI_input)\n",
    "def produce_image_UI(path: str) -> str:\n",
    "    \"\"\"This is a UI function. Produces the JSON for a general UI page about an image.\"\"\"\n",
    "    data = {\"component\":\"Image\", \"props\":{\"url\":path}}\n",
    "    return  json.dumps(data)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00a3ae-4268-4fcf-88e7-f9119fd623a9",
   "metadata": {},
   "source": [
    "<h1> Registering Tools </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65107d1d-f7f7-4083-8b05-267b22cfa3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [design_logo_concepts]\n",
    "functions = [convert_to_openai_function(f) for f in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca7ea53-d733-4b40-af92-96384dce51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_tools = [produce_image_UI]\n",
    "ui_functions = [convert_to_openai_function(f) for f in ui_tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7255906a-a58d-452c-af65-e15256faece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_dictionary = {\n",
    "        \"design_logo_concepts\": design_logo_concepts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8116cde-8dcf-435a-86e6-aa3f706accd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_tool_dictionary = {\n",
    "    \"produce_image_UI\": produce_image_UI\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b705b4-7e85-4f76-ae8f-7f9e9177298f",
   "metadata": {},
   "source": [
    "<h1> Setting up LLM Prompts </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "273b5488-214c-4ece-bdb8-1af2317310b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_message = \"You are helpful assistant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5cea0ea-cc8b-4991-9048-9d8a10963208",
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitivie_ui_instruction_I = \"Should the output to the following prompt be a html page or text? Answer 'Yes' if you think a html page\" +\\\n",
    "    \" is an appropriate option and 'No' if text is enough. The prompt is as follows:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3489a20-a28c-4615-b06e-5f7d1aa5c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitive_ui_instruction_UI = \"Your task is to choose a function from the available options that best matches your ideal UI page\" +\\\n",
    "    \" that will serve as output for information from the scratch pad. Return a function call to it with the appropriate arguments\" +\\\n",
    "    \" and nothing else.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9258b82-889b-495b-b8f7-74f2628a39cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitive_ui_instruction_html = \"Your task is to present the information from the scratch pad in html. Produce fully functioning\" +\\\n",
    "    \" and standalone html code (i.e. no references to images you don't have but feel free to use image references from the scratch\" +\\\n",
    "    \" pad but if there are no image references in the scratch pad don't make them up) that I can take and output immediately with no edits.\" +\\\n",
    "    \" Assume all the images are 1024 by 1024 pixels so make sure to properly size the images so they aren't too big on the screen.\" +\\\n",
    "    \"Return only the html code, and nothing else. Do not provide any commentary about the code or any of your commands.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d326449-4f28-487c-b6ed-f4bd9bc09833",
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitive_ui_instruction_text = \"Answer what is in the scratchpad. Do not comment on this instruction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f9b88d-89d8-45ed-9cf1-5249c0e028af",
   "metadata": {},
   "source": [
    "<h1> Initializing Chains + Agent </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7b33ba-2f41-4dc7-9b9e-b674a48927b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_version = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70348d46-1b2e-4217-8ed1-f7b83b6d0ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "init_prompt_model = ChatOpenAI(model_name= gpt_version, temperature=0).bind(functions=functions)\n",
    "cognitive_ui_model = ChatOpenAI(model_name=gpt_version, temperature=0).bind(functions=ui_functions)\n",
    "no_func_model = ChatOpenAI(model_name=gpt_version, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "227d1eda-1ff8-464e-98ef-ddd336d5a70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", agent_system_message),\n",
    "    (\"user\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3a640b-3374-438f-b88a-420c363bfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt_chain = prompt | init_prompt_model | OpenAIFunctionsAgentOutputParser()\n",
    "cognitivie_ui_chain =  prompt | cognitive_ui_model | OpenAIFunctionsAgentOutputParser()\n",
    "no_func_chain = prompt | no_func_model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d890c8a-e627-4d97-b212-cb42ecddda03",
   "metadata": {},
   "source": [
    "<h1> UI Output Generators </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ca07222-4008-47e5-b601-6679c0f301b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_ui_output(user_input, intermediate_steps):\n",
    "    result = cognitivie_ui_chain.invoke({\n",
    "        \"input\": cognitive_ui_instruction_UI,\n",
    "        \"agent_scratchpad\": format_to_openai_functions(intermediate_steps) + [user_input]\n",
    "    })\n",
    "    tool = ui_tool_dictionary[result.tool]\n",
    "    observation = tool.run(result.tool_input)\n",
    "    return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "128e76d3-54d8-47d4-9b92-0a023072a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_html(user_input, intermediate_steps):\n",
    "    result = no_func_chain.invoke({\n",
    "        \"input\": cognitive_ui_instruction_html,\n",
    "        \"agent_scratchpad\": format_to_openai_functions(intermediate_steps) + [user_input]\n",
    "    })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563a57b-c09a-460e-9f19-ccccee19178e",
   "metadata": {},
   "source": [
    "<h1> Agent Runnable </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10d03ead-af68-436d-a668-2077b5225b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(user_input, ui_producer=produce_ui_output):\n",
    "    \"\"\"\n",
    "    Runs the UI agent which will return a tuple of (LLM Response, Is it calling a UI Function)\n",
    "    \"\"\"\n",
    "    intermediate_steps = []\n",
    "    result = init_prompt_chain.invoke({\n",
    "        \"input\": user_input,\n",
    "        \"agent_scratchpad\": format_to_openai_functions(intermediate_steps)\n",
    "    })\n",
    "    # Are we calling the functions?\n",
    "    if not isinstance(result, AgentFinish):\n",
    "        # Run first non-UI function\n",
    "        tool = tool_dictionary[result.tool]\n",
    "        observation = tool.run(result.tool_input)\n",
    "        intermediate_steps.append((result, observation))\n",
    "    # Cognitive UI Steps\n",
    "    result = no_func_chain.invoke({\n",
    "        \"input\": cognitivie_ui_instruction_I + user_input,\n",
    "        \"agent_scratchpad\": []\n",
    "    })\n",
    "    print(result)\n",
    "    if result.log.lower() == \"yes\":\n",
    "        return ui_producer(user_input, intermediate_steps) , True\n",
    "    else:\n",
    "        result = no_func_chain.invoke({\n",
    "            \"input\": cognitive_ui_instruction_text,\n",
    "            \"agent_scratchpad\": [user_input]\n",
    "        })\n",
    "        return result.log, False\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a247208-f77a-41bc-bbbf-b70302d90a02",
   "metadata": {},
   "source": [
    "<h1>Testing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb07dbd5-94eb-4b76-ae37-f38467f2f94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'No'} log='No'\n",
      "('The scratchpad is empty. How can I assist you today?', False)\n"
     ]
    }
   ],
   "source": [
    "print(run_agent(\"Hello!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8897b2b2-13ac-4a27-832e-ee6e666966c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n",
      "('{\"component\": \"Image\", \"props\": {\"url\": \"s3://designs/logo_3.jpg\"}}', True)\n"
     ]
    }
   ],
   "source": [
    "print(run_agent(\"Design me a big red logo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47adf1a6-fa52-44db-8209-dd553cffedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n",
      "('{\"component\": \"Image\", \"props\": {\"url\": \"cornell_university.jpg\"}}', True)\n"
     ]
    }
   ],
   "source": [
    "print(run_agent(\"Tell me a bit about Cornell University, I hear they are also reffered to as Big Red.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed37598-a70e-4533-a1f2-121311ec0605",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n",
      "('{\"component\": \"Image\", \"props\": {\"url\": \"s3://designs/logo_1.jpg\"}}', True)\n"
     ]
    }
   ],
   "source": [
    "print(run_agent(\"Make me a nice UI page about the movie 'Dune'\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b98af9-a90c-4eaa-a594-7b36c88f54c4",
   "metadata": {},
   "source": [
    "<h1> Direct HTML Output by LLM </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab110720-abfa-4e06-9b5a-bfceeda77360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Big Red Logo</title>\n",
       "    <style>\n",
       "        body {\n",
       "            display: flex;\n",
       "            justify-content: center;\n",
       "            align-items: center;\n",
       "            height: 100vh;\n",
       "            margin: 0;\n",
       "        }\n",
       "\n",
       "        .logo {\n",
       "            max-width: 50%;\n",
       "            height: auto;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "\n",
       "<body>\n",
       "    <img src=\"s3://designs/logo_3.jpg\" alt=\"Big Red Logo\" class=\"logo\">\n",
       "</body>\n",
       "\n",
       "</html>\n",
       "```  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_code = run_agent(\"Design me a big red logo\", produce_html)[0].log\n",
    "display(HTML(html_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c974803a-f864-46d9-8570-de4a1ba44334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Robot Club Application</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "            margin: 0;\n",
       "            padding: 0;\n",
       "            background-color: #f0f0f0;\n",
       "        }\n",
       "\n",
       "        .container {\n",
       "            max-width: 600px;\n",
       "            margin: 20px auto;\n",
       "            padding: 20px;\n",
       "            background-color: #fff;\n",
       "            border-radius: 5px;\n",
       "            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);\n",
       "        }\n",
       "\n",
       "        h1 {\n",
       "            text-align: center;\n",
       "            color: #333;\n",
       "        }\n",
       "\n",
       "        label {\n",
       "            font-weight: bold;\n",
       "        }\n",
       "\n",
       "        input[type=\"text\"],\n",
       "        input[type=\"email\"],\n",
       "        textarea {\n",
       "            width: 100%;\n",
       "            padding: 8px;\n",
       "            margin: 5px 0 15px;\n",
       "            border: 1px solid #ccc;\n",
       "            border-radius: 4px;\n",
       "            box-sizing: border-box;\n",
       "        }\n",
       "\n",
       "        input[type=\"submit\"] {\n",
       "            background-color: #4CAF50;\n",
       "            color: white;\n",
       "            padding: 10px 15px;\n",
       "            border: none;\n",
       "            border-radius: 4px;\n",
       "            cursor: pointer;\n",
       "            width: 100%;\n",
       "        }\n",
       "\n",
       "        input[type=\"submit\"]:hover {\n",
       "            background-color: #45a049;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "\n",
       "<body>\n",
       "    <div class=\"container\">\n",
       "        <h1>Robot Club Application Form</h1>\n",
       "        <form action=\"#\" method=\"post\">\n",
       "            <label for=\"name\">Name:</label>\n",
       "            <input type=\"text\" id=\"name\" name=\"name\" required>\n",
       "\n",
       "            <label for=\"email\">Email:</label>\n",
       "            <input type=\"email\" id=\"email\" name=\"email\" required>\n",
       "\n",
       "            <label for=\"message\">Why do you want to join the Robot Club?</label>\n",
       "            <textarea id=\"message\" name=\"message\" rows=\"4\" required></textarea>\n",
       "\n",
       "            <input type=\"submit\" value=\"Submit\">\n",
       "        </form>\n",
       "    </div>\n",
       "</body>\n",
       "\n",
       "</html>\n",
       "```  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_input = \"Make me a form for applying to my club about robots.\"\n",
    "bale_html_code = run_agent(user_input, produce_html)[0].log\n",
    "display(HTML(bale_html_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d14cb7e-a003-415e-937f-18163ccb64c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Christian Bale Movies</title>\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "            background-color: #f4f4f4;\n",
       "            margin: 0;\n",
       "            padding: 0;\n",
       "        }\n",
       "\n",
       "        .container {\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            padding: 20px;\n",
       "            background-color: #fff;\n",
       "            border-radius: 5px;\n",
       "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n",
       "        }\n",
       "\n",
       "        h1 {\n",
       "            color: #333;\n",
       "            text-align: center;\n",
       "        }\n",
       "\n",
       "        .movie {\n",
       "            margin-bottom: 20px;\n",
       "            padding: 10px;\n",
       "            border: 1px solid #ccc;\n",
       "            border-radius: 5px;\n",
       "        }\n",
       "\n",
       "        .movie img {\n",
       "            max-width: 100px;\n",
       "            height: auto;\n",
       "            float: left;\n",
       "            margin-right: 10px;\n",
       "        }\n",
       "\n",
       "        .movie h2 {\n",
       "            margin-top: 0;\n",
       "            color: #333;\n",
       "        }\n",
       "\n",
       "        .movie p {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        .movie a {\n",
       "            color: #007bff;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "\n",
       "<body>\n",
       "    <div class=\"container\">\n",
       "        <h1>Christian Bale Movies</h1>\n",
       "        <div class=\"movie\">\n",
       "            <img src=\"logo_1.jpg\" alt=\"Movie 1\">\n",
       "            <h2>Movie 1</h2>\n",
       "            <p>Description of Movie 1.</p>\n",
       "            <p><a href=\"https://www.imdb.com/\">IMDB Link</a></p>\n",
       "        </div>\n",
       "    </div>\n",
       "</body>\n",
       "\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_input = \"Provide me with a colorful list of all the movies Christain Bale played in along with links\" +\\\n",
    "    \" to them in IMDB and pictures and a short description\"\n",
    "bale_html_code = run_agent(user_input, produce_html)[0].log\n",
    "display(HTML(bale_html_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "781ef577-656f-4506-b858-22a6db2bb0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Milk Chocolate Ad</title>\n",
      "    <style>\n",
      "        body {\n",
      "            font-family: Arial, sans-serif;\n",
      "            text-align: center;\n",
      "            background-color: #f7f7f7;\n",
      "            margin: 0;\n",
      "            padding: 0;\n",
      "        }\n",
      "\n",
      "        .ad-container {\n",
      "            max-width: 800px;\n",
      "            margin: 20px auto;\n",
      "            background-color: #fff;\n",
      "            border-radius: 10px;\n",
      "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
      "            padding: 20px;\n",
      "        }\n",
      "\n",
      "        h1 {\n",
      "            color: #333;\n",
      "        }\n",
      "\n",
      "        p {\n",
      "            color: #666;\n",
      "        }\n",
      "\n",
      "        img {\n",
      "            max-width: 100%;\n",
      "            height: auto;\n",
      "            border-radius: 5px;\n",
      "            margin-top: 20px;\n",
      "        }\n",
      "    </style>\n",
      "</head>\n",
      "\n",
      "<body>\n",
      "    <div class=\"ad-container\">\n",
      "        <h1>Indulge in Our Delicious Milk Chocolate!</h1>\n",
      "        <p>Experience the rich and creamy taste of our premium milk chocolate. Perfect for any occasion.</p>\n",
      "        <img src=\"s3://designs/logo_5.jpg\" alt=\"Milk Chocolate\">\n",
      "    </div>\n",
      "</body>\n",
      "\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Make me a colorful ad for a milk chocolate product I am making.\"\n",
    "html_code = run_agent(user_input, produce_html)[0].log\n",
    "print(html_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee1b6c-6cba-4454-824a-fc97729a9aa0",
   "metadata": {},
   "source": [
    "<h1>Conclusions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef780f9-6352-4386-93fb-7dacbd250a50",
   "metadata": {},
   "source": [
    "<h3> Analysis of following 'Should the output be UI?' (2/16/2024) </h3> \n",
    "I have discovered that giving ChatGPT a long and complicated write-up followed by options followed by the expectation to execute one of the options resulted in tremendously poor decision making (almost always choosing the first option). I have had more success with reducing the mental difficulty of each query into first a simple yes/no question and then dealing with each option separately depending on the answer. An interesting trait I've detected that even with the yes/no question ChatGPT is more likely to say no when the user direclty asks for a UI page/output and more likely to say yes to prompts asking for explanation/description (i.e. 'Tell me what Cornell is?'). In any case, the prompt's wording is incredibly important and has to be fine-tuned to not make the model always say 'Yes'(UI output would be better) as ChatGPT does have a bias towards choosing the UI output format. One reason for this is that ChatGPT has a pre-disposition to be helpful and optimistic so when your prompt includes phrases like 'benefits the user' (which mine does) it is more likely to agree as to benefit the user the most, even if it is overkill. That being said, it becomes very cautious on long prompts and is difficult to persuade to choose the UI option (Laziness?). Interestingly enough, it is more likely to say yes when it has some former function call in its scratchpad.\n",
    "<br/><br/>\n",
    "Interestingly enough, it is far more likely to say yes to a UI format for a complicated prompt when you make it pretend it is a customer. As soon as you put in a command word like 'Make' it largely ignores the Yes/No question and answers directly. Telling it is an all powerful LLM makes it say yes to the UI page every time.\n",
    "<br/><br/>\n",
    "The system message, I realized, is incredibly powerful and the LLM's answers depend significantly on what is in the system message.\n",
    "<br/><br/>\n",
    "Putting the prompt or scratchpad info at the end makes the LLM much more likely to answer the question at hand than start concentrating on what the scratchpad is asking. This indicates it places heavy emphasis on commands that come first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa80d02-00da-44e6-8328-b2c82d983179",
   "metadata": {},
   "source": [
    "<h3>Analysis of the initial attempt to make the LLM produce its own HTML code directly (2/16/2024)</h3>\n",
    "\n",
    "In general it is able to construct a simple html file quite well. I had to give it explicit instructions to not comment or talk about the code as it has a big tendency to explain what it is doing (possibly a sign of its fine-tuned cautiosness). Even for a long prompt, the smallest and seemingly inconsequential changes made it change its html output completely and even though it was explicitly told to not hallucinate image references it struggled with this command in particular.\n",
    "<br/><br/>\n",
    "It also fails to grasp all the details of the prompt. If I say I want a colorful list then it tends to ignore it but has the ability to make very nice html pages that reflect the main points of my request (look at the Christian Bale output above). It is smart enough to make dummy buttons and knows not to make up random links to connect the button to.\n",
    "<br/><br/>\n",
    "Very impressively, even though it was never explicitly told to do so, it proactively made CSS styles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83c95b-9a94-4ab4-922b-056af070addb",
   "metadata": {},
   "source": [
    "<h1> Additional Tests & Expansion of Capabilities (2/17/2024-3/4/2024) </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35794b23-c2c1-473b-97c4-c03557a766ff",
   "metadata": {},
   "source": [
    "<h2> Custom Imports for this section </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3b16bdc-382d-4b48-abe3-d86938927e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbad70-148e-4bde-8931-7dd7cd19e945",
   "metadata": {},
   "source": [
    "<h2> Testing Image Generation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2eafab11-74a1-41e0-b8b2-30118325b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM_image_generate_input(BaseModel):\n",
    "    prompt: str = Field(... , description=f\"A detailed description of the image you want to generate\")\n",
    "\n",
    "@tool(args_schema=LLM_image_generate_input)\n",
    "def image_generate(prompt: str, model=\"dall-e-2\", size=\"1024x1024\", should_time=False):\n",
    "    \"\"\"\n",
    "    Generates images based on the provided prompt\n",
    "    \"\"\"\n",
    "    prev = time.perf_counter()\n",
    "    response = client.images.generate(\n",
    "      model=model,\n",
    "      prompt=prompt,\n",
    "      size=size,\n",
    "      quality=\"standard\",\n",
    "      n=1,\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    if should_time:\n",
    "        print(f\"Time it took to produce {model}'s Image:{end-prev}s\", )\n",
    "    return response.data[0].url\n",
    "\n",
    "llm_ready_image_generate = convert_to_openai_function(image_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d8e2c02-0cc1-4dcc-8d21-7fc65ae89117",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseTool.__call__() got an unexpected keyword argument 'should_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# DALLE-3\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dalle_3_image_url \u001b[38;5;241m=\u001b[39m \u001b[43mimage_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA white siamese cat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdall-e-3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshould_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# DALLE-2\u001b[39;00m\n\u001b[1;32m      7\u001b[0m dalle_2_image_url \u001b[38;5;241m=\u001b[39m image_generate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA white siamese cat\u001b[39m\u001b[38;5;124m\"\u001b[39m, should_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseTool.__call__() got an unexpected keyword argument 'should_time'"
     ]
    }
   ],
   "source": [
    "### Trying to create images via DALLE-3 Prompts\n",
    "client = openai.OpenAI()\n",
    "\n",
    "# DALLE-3\n",
    "dalle_3_image_url = image_generate(\"A white siamese cat\", \"dall-e-3\", should_time=True)\n",
    "# DALLE-2\n",
    "dalle_2_image_url = image_generate(\"A white siamese cat\", should_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78228c9f-6c47-4355-b564-992460be551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dalle_3_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1caae00-e3b0-4f1b-8fba-eaf94adb9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dalle_2_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91be3e29-cca4-4ff6-8220-99470ef2ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DALLE-3 is on average slower than DALLe-2 with marginal photo improvements \n",
    "### (There are also a number of limits on the throughput of DALLe-3 image production). Thus I decided to proceed\n",
    "### with DALLe-2 as our image producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9676d5-d630-44ef-88ec-89480e630880",
   "metadata": {},
   "source": [
    "<h2>False Image Detection in Produced HTML Code</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35edb346-30be-49d2-a166-0e74d1022cee",
   "metadata": {},
   "source": [
    "<h3> Implementation </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97a31010-3ecc-4148-ae54-91cd5062f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "image_detection_prompt = \"Below you will be provided with html code, please provide all the image sources (src) as strings in a python list format \" +\\\n",
    "    \"in the order they are found in the html document. Provide only the list (with proper square brackets) as normal text (no code blocks),\" +\\\n",
    "    \"no other commentary or text. The html code:\"\n",
    "def image_correction_prompt(number): \n",
    "    return f\"Replace the {number}th image in the html code provided to you in the scratchpad (I am working in the order images are found in the html\" +\\\n",
    "        \" document) with an accurate and believable replacemenet image produced by a function you have access to by calling that function. Make sure\" +\\\n",
    "        \" the prompt is acceptable under openAI image generation guidelines and thus copyright free\"\n",
    "def image_insertion_prompt(number, img_src_list):\n",
    "    return f\"There are {number} images in html code provided to you in the scratchpad. I want you to take the following ordered list of image sources\" +\\\n",
    "        \" (ordered in the order they are found in the html document) and replace the image sources in html code and return the updated html code. While\" +\\\n",
    "        \" you are at it. All the new images are 1024x1024 so adjust the html code to make the images look nice in the html page. Provide only\" +\\\n",
    "        \"the html code, no commentary or discussion or affirmations, only the code. The ordered list of replacement image sources:\"+str(img_src_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "871bfd43-380c-4a6d-a9ee-359a1b4bd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "image_correction_model = ChatOpenAI(model_name=gpt_version, temperature=0).bind(functions=[llm_ready_image_generate])\n",
    "# Chains\n",
    "image_correction_chain = prompt | image_correction_model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "120585d4-954a-48f6-ae35-7a15b9cd34e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def is_image_url_valid(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.RequestException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6cb695d-ec8c-4fca-8304-58df3f7dcb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "def image_modification_agent(input_html_code):\n",
    "    intermediate_steps = []\n",
    "    result = init_prompt_chain.invoke({\n",
    "        \"input\": image_detection_prompt+input_html_code,\n",
    "        \"agent_scratchpad\": intermediate_steps\n",
    "    })\n",
    "    intermediate_steps.append(input_html_code)\n",
    "    url_list = ast.literal_eval(result.log)\n",
    "    new_url_list = []\n",
    "    for i, image_url in enumerate(url_list):\n",
    "        if not is_image_url_valid(image_url):\n",
    "            result = image_correction_chain.invoke({\n",
    "                        \"input\": image_correction_prompt(1),\n",
    "                        \"agent_scratchpad\": intermediate_steps\n",
    "                    })\n",
    "            new_image_url = image_generate(result.tool_input)\n",
    "            new_url_list.append(new_image_url)\n",
    "        else:\n",
    "            new_url_list.append(image_url)\n",
    "    result = init_prompt_chain.invoke({\n",
    "        \"input\": image_insertion_prompt(len(new_url_list), new_url_list),\n",
    "        \"agent_scratchpad\": intermediate_steps\n",
    "    })  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ecc5949-ebb2-454a-8afa-491c2cf5a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine agents\n",
    "def gen_html(user_input):\n",
    "    original_html_code, is_ui_output = run_agent(user_input, produce_html)\n",
    "    if is_ui_output:\n",
    "        corrected_html_code = image_modification_agent(original_html_code.log)\n",
    "        display(HTML(corrected_html_code.log))\n",
    "    else:\n",
    "        print(original_html_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b4208-7645-417f-89b0-34a95dbe3dd6",
   "metadata": {},
   "source": [
    "<h2> Testing Image Generation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f43878-e2aa-49af-9ee3-23b515d5c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_html(\"How to make spaghetti bolognese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d4055-4b1d-4d35-981c-9c876471e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_html(\"A visual guide to making Spaghetti Bolognese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44e658-8e21-4050-8cca-eec03394c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_html(\"A step-by-step guide to making Spaghetti Bolognese with accompanying images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dcef38-0e5d-4c80-aa1f-4874e7992b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_html(\"Make a cool poster for a sci-fi movie set in a desert planet that I am making called 'Sands'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7cfff-7cdb-47d0-a66f-71d7147be24b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_html(\"Make a colourful birthday invite card!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d38c00b-f4fc-4f01-bfff-511979d66254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'Yes'} log='Yes'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgen_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMake a form for applying to Cornell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m, in \u001b[0;36mgen_html\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      3\u001b[0m original_html_code, is_ui_output \u001b[38;5;241m=\u001b[39m run_agent(user_input, produce_html)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_ui_output:\n\u001b[0;32m----> 5\u001b[0m     corrected_html_code \u001b[38;5;241m=\u001b[39m \u001b[43mimage_modification_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_html_code\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     display(HTML(corrected_html_code\u001b[38;5;241m.\u001b[39mlog))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[38], line 17\u001b[0m, in \u001b[0;36mimage_modification_agent\u001b[0;34m(input_html_code)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_image_url_valid(image_url):\n\u001b[1;32m     13\u001b[0m     result \u001b[38;5;241m=\u001b[39m image_correction_chain\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: image_correction_prompt(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m: intermediate_steps\n\u001b[1;32m     16\u001b[0m             })\n\u001b[0;32m---> 17\u001b[0m     new_image_url \u001b[38;5;241m=\u001b[39m \u001b[43mimage_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     new_url_list\u001b[38;5;241m.\u001b[39mappend(new_image_url)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/tools.py:501\u001b[0m, in \u001b[0;36mBaseTool.__call__\u001b[0;34m(self, tool_input, callbacks)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tool_input: \u001b[38;5;28mstr\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    500\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Make tool callable.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/tools.py:401\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    400\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mstr\u001b[39m(observation), color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    405\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/tools.py:358\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m     parsed_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_input(tool_input)\n\u001b[1;32m    356\u001b[0m     tool_args, tool_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    357\u001b[0m     observation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 358\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    360\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[1;32m    361\u001b[0m     )\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/langchain_core/tools.py:683\u001b[0m, in \u001b[0;36mStructuredTool._run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[1;32m    675\u001b[0m     new_argument_supported \u001b[38;5;241m=\u001b[39m signature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    677\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\n\u001b[1;32m    678\u001b[0m             \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m    679\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    680\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    681\u001b[0m         )\n\u001b[1;32m    682\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_argument_supported\n\u001b[0;32m--> 683\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[34], line 10\u001b[0m, in \u001b[0;36mimage_generate\u001b[0;34m(prompt, model, size, should_time)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mGenerates images based on the provided prompt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m prev \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43mquality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstandard\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_time:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/openai/resources/images.py:252\u001b[0m, in \u001b[0;36mImages.generate\u001b[0;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImagesResponse:\n\u001b[1;32m    212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    Creates an image given a prompt.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/images/generations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstyle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageGenerateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/openai/_base_client.py:918\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    915\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 918\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    924\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpx/_client.py:915\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    907\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    911\u001b[0m )\n\u001b[1;32m    913\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 915\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpx/_client.py:943\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 943\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpx/_client.py:980\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    978\u001b[0m     hook(request)\n\u001b[0;32m--> 980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpx/_client.py:1016\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1013\u001b[0m     )\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1016\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1020\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpx/_transports/default.py:231\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    218\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    219\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    220\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 231\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    236\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    237\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    238\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    239\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:268\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_closed(status)\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:251\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# up as HTTP/1.1.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool_lock:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;66;03m# Maintain our position in the request queue, but reset the\u001b[39;00m\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# status so that the request becomes queued again.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:133\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:111\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    105\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    106\u001b[0m     (\n\u001b[1;32m    107\u001b[0m         http_version,\n\u001b[1;32m    108\u001b[0m         status,\n\u001b[1;32m    109\u001b[0m         reason_phrase,\n\u001b[1;32m    110\u001b[0m         headers,\n\u001b[0;32m--> 111\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    113\u001b[0m         http_version,\n\u001b[1;32m    114\u001b[0m         status,\n\u001b[1;32m    115\u001b[0m         reason_phrase,\n\u001b[1;32m    116\u001b[0m         headers,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    120\u001b[0m     status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m    121\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m     },\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:176\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    173\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:212\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 212\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1263\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/ssl.py:1136\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen_html(\"Make a form for applying to Cornell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "050320ea-9e00-4ca6-a134-ae420d8de4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_values={'output': 'No'} log='No'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "```html\n",
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "    <style>\n",
       "        img {\n",
       "            width: 300px;\n",
       "            height: 300px;\n",
       "            object-fit: cover;\n",
       "            margin: 10px;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "    <img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-CRWrBq65zdTy03WsZ2bR8nw7/user-YJtuVKh5srkktPqUJ94RfYo9/img-kRjy4x9P84l7uGzr2zdtImwe.png?st=2024-03-05T19%3A50%3A38Z&se=2024-03-05T21%3A50%3A38Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-05T14%3A33%3A56Z&ske=2024-03-06T14%3A33%3A56Z&sks=b&skv=2021-08-06&sig=wfEe8CQxX2%2BT7Zrhm5icLcAGNoEzPgVc37q2t/qg7iA%3D\">\n",
       "    <img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-CRWrBq65zdTy03WsZ2bR8nw7/user-YJtuVKh5srkktPqUJ94RfYo9/img-B0aRIHhCCsMH4EcYujsYq0ic.png?st=2024-03-05T19%3A50%3A47Z&se=2024-03-05T21%3A50%3A47Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-05T18%3A13%3A14Z&ske=2024-03-06T18%3A13%3A14Z&sks=b&skv=2021-08-06&sig=Q9rQnBV9t8SXkpImVn5qsiYK6oxlkT%2BZhbCNkmLVPEY%3D\">\n",
       "    <img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-CRWrBq65zdTy03WsZ2bR8nw7/user-YJtuVKh5srkktPqUJ94RfYo9/img-14XaELZScC7hrrfbjdS01qDG.png?st=2024-03-05T19%3A51%3A01Z&se=2024-03-05T21%3A51%3A01Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-05T18%3A43%3A06Z&ske=2024-03-06T18%3A43%3A06Z&sks=b&skv=2021-08-06&sig=BoGq2NRQi9y94w/Ff2qQCjU3bywrnJcCgVD4BIAGGOo%3D\">\n",
       "    <img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-CRWrBq65zdTy03WsZ2bR8nw7/user-YJtuVKh5srkktPqUJ94RfYo9/img-vRUPyMZsfeMiTpKz24UXkUmT.png?st=2024-03-05T19%3A51%3A11Z&se=2024-03-05T21%3A51%3A11Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-05T15%3A29%3A52Z&ske=2024-03-06T15%3A29%3A52Z&sks=b&skv=2021-08-06&sig=aXruff5rkzXVnay7hZyUf%2Bi4qnKkGplEuEFoUfD7J9c%3D\">\n",
       "    <img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-CRWrBq65zdTy03WsZ2bR8nw7/user-YJtuVKh5srkktPqUJ94RfYo9/img-6fdXSzmaoO4J1OckfgvvzGX8.png?st=2024-03-05T19%3A51%3A21Z&se=2024-03-05T21%3A51%3A21Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-05T15%3A15%3A00Z&ske=2024-03-06T15%3A15%3A00Z&sks=b&skv=2021-08-06&sig=DKO9w1aasGgqAyDS9FiGc6E8noWjEcxf2bisNfMCxao%3D\">\n",
       "</body>\n",
       "</html>\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gen_html(\"Recommend me 5 romantic comedy movies to watch this evening.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5bd198-6558-41ab-b8fa-ecd3fae72209",
   "metadata": {},
   "source": [
    "<h2> Analysis </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9b417-4f7d-4507-a1f0-c63ec41555fe",
   "metadata": {},
   "source": [
    "<h3> Random Decision Making</h3>\n",
    "Even with the same prompt at 0 temperature ChatGPT frequently flip flops between deciding a prompt needs a UI response or doesn't further complicating the quality of the decision process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac2e1e-3543-49e7-906a-eb945c8c3bd7",
   "metadata": {},
   "source": [
    "<h3> Mis-handling Images </h3>\n",
    "Even when explicitly told to do so and given exact image dimensions, the LLM poorly sizes the images often giving the entire screen over to them leading to a very unpleasant looking UI page. In general, the UI seems to poorly combine images into UI pages as seen by the tests above showing a distinct lack of spatial and aesthetic awarness which shouldn't be surprising for an LLM (which neither has nor was trained to have "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d983030-b386-431a-833b-dffed5d03313",
   "metadata": {},
   "source": [
    "<h3> Over-dependence on Images </h3>\n",
    "Prompts that use words like 'visual' trigger the LLM to put all contents of a UI page into the image which DALLe-2 cannot handle leading to a very barren and empty page with just a massive central image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314de3e4-66e8-4752-b5d3-fd78f109be5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
